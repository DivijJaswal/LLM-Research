{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhELWq//HK5C9Z8a6KNXK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivijJaswal/LLM-Research/blob/main/Working_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DivijJaswal/LLM-Research.git\n",
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "!pip install bert_score\n",
        "!pip install meteor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LaInT0Q92COJ",
        "outputId": "b54f2dde-50df-4c0f-fc4a-dd1b38ef6e5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LLM-Research' already exists and is not an empty directory.\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.4.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.44.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n",
            "Collecting meteor\n",
            "  Downloading meteor-2.0.16-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting bgzip<0.6.0,>=0.5.0 (from meteor)\n",
            "  Downloading bgzip-0.5.0.tar.gz (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting biom-format<3.0.0,>=2.1.15 (from meteor)\n",
            "  Downloading biom-format-2.1.16.tar.gz (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cogent3<2025.0.0,>=2024.2.5a1 (from meteor)\n",
            "  Downloading cogent3-2024.7.19a6-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting ete3<4.0.0,>=3.1.3 (from meteor)\n",
            "  Downloading ete3-3.1.3.tar.gz (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging<24.0,>=23.2 (from meteor)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from meteor) (2.2.2)\n",
            "Collecting pyarrow<16.0.0,>=15.0.0 (from meteor)\n",
            "  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pysam<0.23.0,>=0.22.0 (from meteor)\n",
            "  Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (8.1.7)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (1.13.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from biom-format<3.0.0,>=2.1.15->meteor) (3.11.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (5.2.0)\n",
            "Collecting loky (from cogent3<2025.0.0,>=2024.2.5a1->meteor)\n",
            "  Downloading loky-3.4.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numba>0.53 in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (0.60.0)\n",
            "Collecting scitrack (from cogent3<2025.0.0,>=2024.2.5a1->meteor)\n",
            "  Downloading scitrack-2024.10.8-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting stevedore (from cogent3<2025.0.0,>=2024.2.5a1->meteor)\n",
            "  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (4.66.5)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.2->meteor) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.2->meteor) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.2->meteor) (2024.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>0.53->cogent3<2025.0.0,>=2024.2.5a1->meteor) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.2->meteor) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from loky->cogent3<2025.0.0,>=2024.2.5a1->meteor) (2.2.1)\n",
            "Collecting pbr>=2.0.0 (from stevedore->cogent3<2025.0.0,>=2024.2.5a1->meteor)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Downloading meteor-2.0.16-py3-none-any.whl (61.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cogent3-2024.7.19a6-py3-none-any.whl (746 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.6/746.6 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (22.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loky-3.4.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scitrack-2024.10.8-py3-none-any.whl (7.8 kB)\n",
            "Downloading stevedore-5.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: bgzip, biom-format, ete3\n",
            "  Building wheel for bgzip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bgzip: filename=bgzip-0.5.0-cp310-cp310-linux_x86_64.whl size=237136 sha256=8c226a20fd88353ce4c21142009dff10a05967b1ef84a60fe2be4c0b6e2f4449\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/b8/56/9367ade000d28a1a7f9439b7c040719e0d2c0152ddf216f5da\n",
            "  Building wheel for biom-format (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for biom-format: filename=biom_format-2.1.16-cp310-cp310-linux_x86_64.whl size=12158968 sha256=59a87cbcb0a3f563a14676817ce5c9bd84ab7d433d2644e28cd7092d6daa24eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/a9/f9/197fd5a0e5bbab5f2e03c89194f6c194bed7af5d7a8c8759f3\n",
            "  Building wheel for ete3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ete3: filename=ete3-3.1.3-py3-none-any.whl size=2273788 sha256=468cd9ceb413ad2694bdd38dee4af6596e1248dbda068b26e6dfddeec3994735\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/72/00/1982bd848e52b03079dbf800900120bc1c20e92e9a1216e525\n",
            "Successfully built bgzip biom-format ete3\n",
            "Installing collected packages: ete3, bgzip, scitrack, pysam, pyarrow, pbr, packaging, loky, stevedore, cogent3, biom-format, meteor\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 16.1.0\n",
            "    Uninstalling pyarrow-16.1.0:\n",
            "      Successfully uninstalled pyarrow-16.1.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.6.1 requires pyarrow<16.2.0a0,>=16.1.0, but you have pyarrow 15.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bgzip-0.5.0 biom-format-2.1.16 cogent3-2024.7.19a6 ete3-3.1.3 loky-3.4.1 meteor-2.0.16 packaging-23.2 pbr-6.1.0 pyarrow-15.0.2 pysam-0.22.1 scitrack-2024.10.8 stevedore-5.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "67b300b3c70c4ab2b37bf4b4c5fad611"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "from huggingface_hub import login\n",
        "import evaluate\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import spacy\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from transformers import logging\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "XezSKDxY1PcA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_breaker = '''\n",
        "                _ ___                /^^\\ /^\\  /^^\\_\n",
        "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
        "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
        " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
        "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
        " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
        "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
        " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
        "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
        "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CQMhUeRB7fuh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(line_breaker)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsL2TLKF7ncL",
        "outputId": "19be8f46-cf2c-42d5-c9e5-f0bd6b027943"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NyoMQTj1BPd",
        "outputId": "deea80bb-9d51-4925-d14e-723ea1ec2ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "login(token = \"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\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "summarizer = pipeline(\"summarization\",tokenizer=tokenizer, model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "references = [\"The shepherd boy raised two false alarms to trick the villagers that the wolf was grazing his sheep. When a real wolf appears, the villagers ignore his call, thinking it's another lie. The wolf attacks his sheep and the boy learns a lesson after raising those false alarms, that lying results in losing people’s trust.\"]\n",
        "\n",
        "def shorten_text(text, chunk_size, method):\n",
        "    \"\"\"\n",
        "    Shortens the text using the specified method.\n",
        "    :param text: The original text to shorten.\n",
        "    :param chunk_size: The size of each chunk if needed.\n",
        "    :param method: Method to shorten the text.\n",
        "    :return: Shortened text.\n",
        "    \"\"\"\n",
        "    if method == \"clipping\":\n",
        "        return text[:chunk_size]\n",
        "\n",
        "    elif method == \"iterative\":\n",
        "        chunks = [' '.join(text.split()[i:i+chunk_size]) for i in range(0, len(text.split()), chunk_size)]\n",
        "        summarized_chunks = [summarizer(chunk, min_length=50, max_length=100, do_sample=False)[0]['summary_text'] for chunk in chunks]\n",
        "        return \" \".join(summarized_chunks)\n",
        "\n",
        "    elif method == \"random_removal\":\n",
        "        words = text.split()\n",
        "        while len(words) > chunk_size:\n",
        "            index_to_remove = random.randint(0, len(words) - 1)\n",
        "            del words[index_to_remove]\n",
        "        return \" \".join(words)\n",
        "\n",
        "    elif method == \"sentence_ranking\":\n",
        "        return tfidf_sentence_ranking(text, chunk_size)\n",
        "\n",
        "    elif method == \"sliding_window\":\n",
        "        return sliding_window(text, chunk_size)\n",
        "\n",
        "    elif method == \"entity_filtering\":\n",
        "        return entity_filtering(text, chunk_size)\n",
        "\n",
        "    elif method == \"summarize_summary\":\n",
        "        return summarize_summary(text, chunk_size)\n",
        "\n",
        "    elif method == \"lsa\":\n",
        "        return lsa_text_summarization(text, chunk_size)\n",
        "\n",
        "def tfidf_sentence_ranking(text, chunk_size):\n",
        "    sentences = text.split('. ')\n",
        "    vectorizer = TfidfVectorizer().fit_transform(sentences)\n",
        "    vectors = vectorizer.toarray()\n",
        "    sentence_scores = np.sum(vectors, axis=1)\n",
        "\n",
        "    ranked_sentences = sorted(((score, i, s) for i, (score, s) in enumerate(zip(sentence_scores, sentences))), reverse=True)\n",
        "    selected_sentences = [s for _, _, s in ranked_sentences[:int(chunk_size / 20)]]\n",
        "    return '. '.join(selected_sentences)\n",
        "\n",
        "def sliding_window(text, chunk_size, overlap=100):\n",
        "    words = text.split()\n",
        "    windows = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        window = words[i:i+chunk_size]\n",
        "        windows.append(\" \".join(window))\n",
        "\n",
        "    summarized_windows = [summarizer(w, min_length=50, max_length=100, do_sample=False)[0]['summary_text'] for w in windows]\n",
        "    return \" \".join(summarized_windows)\n",
        "\n",
        "def entity_filtering(text, chunk_size):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    important_sentences = []\n",
        "    for sent in doc.sents:\n",
        "        if any(ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"DATE\"] for ent in sent.ents):\n",
        "            important_sentences.append(sent.text)\n",
        "        if len(important_sentences) >= chunk_size / 20:\n",
        "            break\n",
        "    return \" \".join(important_sentences)\n",
        "\n",
        "\n",
        "def summarize_summary(text, chunk_size):\n",
        "    \"\"\"\n",
        "    Recursively summarize the text until it is under a desired length.\n",
        "    \"\"\"\n",
        "    summarized_text = text\n",
        "    iteration = 0\n",
        "    while len(summarized_text) > chunk_size:\n",
        "        print(f\"Iteration {iteration + 1}: Text too long. Summarizing again.\")\n",
        "        summarized_text = shorten_text(summarized_text,512,\"iterative\")\n",
        "        iteration += 1\n",
        "    return summarized_text\n",
        "\n",
        "def lsa_text_summarization(text, chunk_size):\n",
        "    \"\"\"\n",
        "    Use Latent Semantic Analysis (LSA) to extract the most important concepts from the text and return the most relevant sentences.\n",
        "    \"\"\"\n",
        "    sentences = text.split('. ')\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(sentences)\n",
        "\n",
        "    lsa_model = TruncatedSVD(n_components=1, n_iter=100)\n",
        "    lsa_model.fit(X)\n",
        "    lsa_scores = lsa_model.transform(X)\n",
        "\n",
        "    # Rank sentences by their relevance to the main topics\n",
        "    ranked_sentences = sorted(((lsa_scores[i, 0], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "    # Select the top N sentences based on LSA scores\n",
        "    selected_sentences = [s for _, s in ranked_sentences[:int(chunk_size / 20)]]\n",
        "    return '. '.join(selected_sentences)\n",
        "\n",
        "def scores(predictions):\n",
        "    bleu = evaluate.load('bleu')\n",
        "    results = bleu.compute(predictions=predictions, references=references)\n",
        "    print(results)\n",
        "\n",
        "    rouge = evaluate.load('rouge')\n",
        "    results = rouge.compute(predictions=predictions,references=references)\n",
        "    print(results)\n",
        "\n",
        "    bertscore = evaluate.load(\"bertscore\")\n",
        "    results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "    print(results)\n",
        "\n",
        "    meteor = evaluate.load('meteor')\n",
        "    results = meteor.compute(predictions=predictions, references=references)\n",
        "    print(results)\n",
        "\n",
        "def summarize_text(input_file,num_beams):\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    print(line_breaker)\n",
        "    print(\"clipping\")\n",
        "    clipped_text = shorten_text(text, 512, \"clipping\")\n",
        "    short_summary = summarizer(clipped_text ,num_beams, min_length = 50, max_length =100,do_sample=False)\n",
        "    print(short_summary)\n",
        "    predictions = [item['summary_text'] for item in short_summary]\n",
        "    scores(predictions=predictions)\n",
        "    print(line_breaker)\n",
        "\n",
        "    print(\"iterative\")\n",
        "    short_summary = shorten_text(text,512,\"iterative\")\n",
        "    print(short_summary)\n",
        "    predictions = [short_summary]\n",
        "    scores(predictions=predictions)\n",
        "    print(line_breaker)\n",
        "\n",
        "    #random removal     not complete\n",
        "    print(\"Random Removal\")\n",
        "    removed_text = shorten_text(text,512,\"random_removal\")\n",
        "    print(len((removed_text.split())))\n",
        "    short_summary = summarizer(removed_text ,num_beams, min_length = 50, max_length =100,do_sample=False)\n",
        "    print(short_summary)\n",
        "    print(line_breaker)\n",
        "\n",
        "    # sentence ranking  not working\n",
        "    print(\"Sentence Ranking\")\n",
        "    ranked_text = shorten_text(text,512,\"sentence_ranking\")\n",
        "    short_summary = summarizer(ranked_text ,num_beams, min_length = 50, max_length =100,do_sample=False)\n",
        "    print(short_summary)\n",
        "    print(line_breaker)\n",
        "\n",
        "    # sliding window not working\n",
        "    print(\"Sliding Window\")\n",
        "    short_summary = shorten_text(text,512,\"sliding_window\")\n",
        "    print(short_summary)\n",
        "    print(line_breaker)\n",
        "\n",
        "    # entity filtering  not working\n",
        "    print(\"Entity Filtering\")\n",
        "    filtered_text = shorten_text(text,512,\"entity_filtering\")\n",
        "    short_summary = summarizer(filtered_text ,num_beams, min_length = 50, max_length =100,do_sample=False)\n",
        "    print(short_summary)\n",
        "    print(line_breaker)\n",
        "\n",
        "    #lsa  not working\n",
        "    print(\"LSA\")\n",
        "    lsa_text = shorten_text(text,512,\"lsa\")\n",
        "    short_summary = summarizer(lsa_text ,num_beams, min_length = 50, max_length =100,do_sample=False)\n",
        "    print(short_summary)\n",
        "    print(line_breaker)\n",
        "\n",
        "    print(\"summarize_summary\")\n",
        "\n",
        "    short_summary = shorten_text(text,512,\"summarize_summary\")\n",
        "    print(short_summary)\n",
        "    predictions = [short_summary]\n",
        "    scores(predictions=predictions)\n",
        "    # medium_summary = summarizer(text ,num_beams, min_length = 100, max_length =150,do_sample=False)\n",
        "    # large_summary = summarizer(text ,num_beams, min_length = 150, max_length =200,do_sample=False)\n",
        "    print(line_breaker)\n",
        "\n",
        "\n",
        "    # print(medium_summary)\n",
        "    # print(large_summary)\n",
        "    # print(results)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_file=\"/content/LLM-Research/text1.txt\"\n",
        "print(input_file)\n",
        "num_beams=5\n",
        "summarize_text(input_file,num_beams)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWJs2WK-2JJv",
        "outputId": "41d9ad44-e88e-4b38-e29a-e904004d7340"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM-Research/text1.txt\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "clipping\n",
            "[{'summary_text': 'The ICC is the international federation responsible for the global governance of the sport of cricket. The Code of Conduct for Players and Player Support Personnel is adopted and implemented as part of the ICC’s continuing efforts to maintain the public image, popularity and integrity of cricket by providing an effective means to deter any participant from conducting them.'}]\n",
            "{'bleu': 0.0, 'precisions': [0.1774193548387097, 0.01639344262295082, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0163934426229508, 'translation_length': 62, 'reference_length': 61}\n",
            "{'rouge1': 0.15384615384615385, 'rouge2': 0.0, 'rougeL': 0.13675213675213677, 'rougeLsum': 0.13675213675213677}\n",
            "{'precision': [0.8186137080192566], 'recall': [0.8293216228485107], 'f1': [0.8239328265190125], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.44.2)'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'meteor': 0.147003173828125}\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "iterative\n",
            "The ICC is the international federation responsible for the global governance of the sport of cricket. The Code of Conduct for Players and Player Support Personnel is adopted and implemented as part of the ICC’s continuing efforts to maintain the public image, popularity and integrity of Cricket. The ICC and the National Cricket Federations shall be responsible for promoting Code of conduct awareness and education. All Umpires and Match Referees officiating in any International Matches are automatically bound by and required to comply with all of the provisions of the ICC Code of Conduct for Match Officials and Match Official Support Personnel; and 1.5.2 where a representative side of a National Cricket Federation participates in an International Tour Match against a domestic or invitational team.\n",
            "{'bleu': 0.0, 'precisions': [0.11450381679389313, 0.015384615384615385, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 2.1475409836065573, 'translation_length': 131, 'reference_length': 61}\n",
            "{'rouge1': 0.12972972972972974, 'rouge2': 0.01092896174863388, 'rougeL': 0.1081081081081081, 'rougeLsum': 0.1081081081081081}\n",
            "{'precision': [0.7842685580253601], 'recall': [0.8222861289978027], 'f1': [0.8028274774551392], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.44.2)'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'meteor': 0.13982362213947222}\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "Random Removal\n",
            "512\n",
            "[{'summary_text': 'The Code Conduct for Players and Player Support Personnel (the “Code Conduct”) is implemented as part of the ICC’s continuing efforts maintain the popularity and integrity of cricket. All Players and Support Personnel are automatically by and required to comply of provisions of the of Conduct. All Umpires and Match Referees officiating any International are also required to follow the Code.'}]\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "Sentence Ranking\n",
            "[{'summary_text': 'The ICC is the international federation responsible for the global governance of the sport of cricket. The Code of Conduct for Players and Player Support Personnel (the “Code of Conduct”) is adopted and implemented as part of the ICC’s continuing efforts to maintain the public image, popularity and integrity of Cricket. It is intended to deter any participant from conducting themselves improperly.'}]\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "Sliding Window\n",
            "The ICC is the international federation responsible for the global governance of the sport of cricket. The Code of Conduct for Players and Player Support Personnel is adopted and implemented as part of the ICC’s continuing efforts to maintain the public image, popularity and integrity of Cricket. The ICC and the National Cricket Federations shall be responsible for promoting Code of conduct awareness and education. All Umpires and Match Referees officiating in any International Matches are automatically bound by and required to comply with all of the provisions of the ICC Code of Conduct. Support Personnel. It is acknowledged that certain Players and Player Support Personnel may also be subject to other rules of National Cricket Federations that govern discipline and/or conduct.\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "Entity Filtering\n",
            "[{'summary_text': 'The ICC is the international federation responsible for the global governance of the sport of cricket. The Code of Conduct for Players and Player Support Personnel is adopted and implemented as part of the ICC’s continuing efforts to maintain the public image, popularity and integrity of Cricket. It provides an effective means to deter any participant from conducting themselves improperly on and off the field of play.'}]\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "LSA\n",
            "[{'summary_text': 'The ICC is the international federation responsible for the global governance of the sport of cricket. The Code of Conduct for Players and Player Support Personnel is adopted and implemented as part of the ICC’s continuing efforts to maintain the public image, popularity and integrity of Cricket. It provides an effective means to deter any participant from conducting themselves improperly.'}]\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n",
            "summarize_summary\n",
            "Iteration 1: Text too long. Summarizing again.\n",
            "Iteration 2: Text too long. Summarizing again.\n",
            "The Code of Conduct for Players and Player Support Personnel is adopted and implemented as part of the ICC’s continuing efforts to maintain the public image, popularity and integrity of Cricket. The ICC and the National Cricket Federations shall be responsible for promoting Code of conduct awareness and education. All Umpires and Match Referees officiating in any International Matches are automatically bound by and required to comply with all of the provisions.\n",
            "{'bleu': 0.0, 'precisions': [0.17105263157894737, 0.02666666666666667, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.2459016393442623, 'translation_length': 76, 'reference_length': 61}\n",
            "{'rouge1': 0.15384615384615385, 'rouge2': 0.015625, 'rougeL': 0.1076923076923077, 'rougeLsum': 0.1076923076923077}\n",
            "{'precision': [0.8030687570571899], 'recall': [0.8233634233474731], 'f1': [0.8130894899368286], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.44.2)'}\n",
            "{'meteor': 0.14385631689602446}\n",
            "\n",
            "                _ ___                /^^\\ /^\\  /^^\\_\n",
            "    _          _@)@) \\            ,,/ '` ~ `'~~ ', `\\.\n",
            "  _/o\\_ _ _ _/~`.`...'~\\        ./~~..,'`','',.,' '  ~:\n",
            " / `,'.~,~.~  .   , . , ~|,   ,/ .,' , ,. .. ,,.   `,  ~\\_\n",
            "( ' _' _ '_` _  '  .    , `\\_/ .' ..' '  `  `   `..  `,   \\_\n",
            " ~V~ V~ V~ V~ ~\\ `   ' .  '    , ' .,.,''`.,.''`.,.``. ',   \\_\n",
            "  _/\\ /\\ /\\ /\\_/, . ' ,   `_/~\\_ .' .,. ,, , _/~\\_ `. `. '.,  \\_\n",
            " < ~ ~ '~`'~'`, .,  .   `_: ::: \\_ '      `_/ ::: \\_ `.,' . ',  \\_\n",
            "  \\ ' `_  '`_    _    ',/ _::_::_ \\ _    _/ _::_::_ \\   `.,'.,`., \\-,-,-,_,_,\n",
            "   `'~~ `'~~ `'~~ `'~~  \\(_)(_)(_)/  `~~' \\(_)(_)(_)/ ~'`\\_.._,._,'_;_;_;_;_;\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DUPluNIl2hOS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}